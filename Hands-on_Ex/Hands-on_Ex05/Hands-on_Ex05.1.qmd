---
title: "Hands-on Exercise 5.1 Global Measures of Spatial Autocorrelation"
author: "Ha Duc Tien"
date: "September 16, 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  warning: false
  message: false
  freeze: true
---

# 1. Overview

In this hands-on exercise, we will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using `spdep` package. By the end to this hands-on exercise, we will be able to:

-   import geospatial data using appropriate function(s) of `sf` package,
-   import csv file using appropriate function of `readr` package,
-   perform relational join using appropriate join function of `dplyr` package,
-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of `spdep` package.
    -   plot Moran scatterplot.
    -   compute and plot spatial correlogram using appropriate function of `spdep` package.
-   provide statistically correct interpretation of GSA statistics.

# 2. Getting Started

## 2.1 The analytical question

In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is **No**. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of [Hunan Provice](https://en.wikipedia.org/wiki/Hunan), People Republic of China.

## 2.2 The Study Area and Data

Two data sets will be used in this hands-on exercise, they are:

-   Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.
-   Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.

## 2.3 Setting the Analytical Tools

Before we get started, we need to ensure that `spdep`, `sf`, `tmap` and `tidyverse` packages of R are currently installed in your R.

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse)
```

# 3. Getting the Data Into R Environment

In this section, we will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.

## 3.1 Import shapefile into r environment

The code chunk below uses [st_read()](https://r-spatial.github.io/sf/reference/st_read.html) of `sf` package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

## 3.2 Import csv file into r environment

Next, we will import Hunan_2012.csv into R by using [read_csv()](https://readr.tidyverse.org/reference/read_delim.html) of `readr` package. The output is R data frame class.

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

## 3.3 Performing relational join

The code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using [left_join()](https://dplyr.tidyverse.org/reference/mutate-joins.html) of `dplyr` package.

```{r}
hunan <- left_join(hunan,hunan2012) %>%
  select(1:4, 7, 15)
```

## 3.4 Visualising Regional Development Indicator

Now, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using `qtm()` of `tmap` package.

```{r, fig.height=9, fig.width=12, dpi=100}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

# 4. Global Measures of Spatial Autocorrelation

In this section, you will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.

## 4.1 Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.

In the code chunk below, [poly2nb()](https://r-spatial.github.io/spdep/reference/poly2nb.html) of `spdep` package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.

More specifically, the code chunk below is used to compute Queen contiguity weight matrix.

```{r}
wm_q <- poly2nb(hunan, 
                queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.

## 4.2 Row-standardised weights matrix

Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.

```{r}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```

::: callout-note
## What can we learn from the code chunk above?

-   The input of [`nb2listw()`](https://r-spatial.github.io/spdep/reference/nb2listw.html) must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.
-   `style` can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).
-   If `zero.policy` is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %\*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.
:::

# 5. Global Measures of Spatial Autocorrelation: Moran’s I

In this section, you will learn how to perform Moran’s I statistics testing by using [moran.test()](https://r-spatial.github.io/spdep/reference/moran.test.html) of `spdep`.

## 5.1 Maron’s I test

The code chunk below performs Moran’s I statistical testing using `moran.test()` of `spdep`.

```{r}
moran.test(hunan$GDPPC, 
           listw=rswm_q, 
           zero.policy = TRUE, 
           na.action=na.omit)
```


**Question: What statistical conclusion can you draw from the output above?**

p-value < 0.05, null hypothesis is rejected and we conclude that the spatial processes promoting the observed pattern of values is not random.

